La base de données avec les colonnes suivants:
  1 colonne M/B (la cellule malade ou bonne)
  10 colonnes de valeur moyennes descriptives numeriques (type float)
  10 colonnes de standart erreur pour les valeurs moyennes
  10 colonnes de avec le resultat le plus pire

Pas de valeur manquants
Pas de duplication
Une colonnes a été suprimée ('Unnamed 32')

Le datavis:
  Boxplots pour chaque colonnes avec le distribution de valeurs de dataset normal et malin.
    *presque pour chaque variable (moyenne) il y a la difference dans les distributions de valeurs moynnes et les plus pire
    (sauf que fractuale dimetion mean)
  Distplot pour le valeur moynees +-st erreur pour M/B
  Heatmap avec coef de correlation pour moyenne et worst value
  Pairplot de moyenne et worst values avec different colors of M/B

Statistique:
  All calculated p-value are very small, e.i their distribution is normal
  Chi-square in this case gives the same value (look in colab)
  One-way ANOVA test

Generated dataframe is in csv file in this repository

With PCA it is determined that 0.75 of total variance is explained by 2 dimentional variables.
By using PCA with unsuperwised clustering it is clean that there are 2 clusters (determined by silhouette_score)

Machine Learning
1. Avec lazypredict on a éstimé 25 classifiers et a choisi 5 avec le Balanced Accuracy score le plus haut.
    LogisticRegression(), SGDClassifier(),LinearSVC(), Perceptron(), SVC()
    and MLP() + RandomForestClassifier()

***  steps 2-4 was runned several times with multiple combination of columns ***

2. For each model there was a choise of scaler between MaxAbsScaler(), MinMaxScaler(), Normalizer(), PowerTransformer(), 
    QuantileTransformer(), RobustScaler(), StandardScaler()
    I create a 2 dataframe with models, scaler and score/number of false negative result

3. Puis ces models ont étaient par GridSearch pour choisi les meiuller hyperparametres.

4. The confusion matrix was used to estimate if its possible to reduce the number of false negative results with the model
  that allows changing of class weights

5. The best models was chosen for staking model ensemble. Final estimator was tested as well to find the best score

The final choise of columns
1. To compare all columns they were normalised with StandartScaler and all visulised in the same plot
2. Columns where was no visual difference between B/M were excluded
3. Columns with a lot of outliers were excluded
4. With the heatmap all columns was grouped according to correlation. If coef of correlation is higher that 0.8 it was included into group
5. Withis each group only column with the highest corr coef with diagnosis was chosen
6. One column with standart deviation that shows the best distribution of B/M was chosen also
